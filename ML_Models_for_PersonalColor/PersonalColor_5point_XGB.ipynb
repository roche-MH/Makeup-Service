{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils, paths\n",
    "import numpy as np\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "def imshow(tit, image) :\n",
    "    plt.title(tit)    \n",
    "    if len(image.shape) == 3 :\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    else :\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"./imgs/no_makeup/xfsy_0068.png\") \n",
    "\n",
    "frame = cv2.imread(\"./imgs/no_makeup/xfsy_0068.png\")\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "rects = detector(gray, 0)  \n",
    "# print(\"Number of faces detected: {}\".format(len(rects)))\n",
    "# for r in rects :\n",
    "#     print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, d in enumerate(rects):\n",
    "#         print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "#             k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "        shape = predictor(gray, d)\n",
    "        shape = face_utils.shape_to_np(shape) #객체 내에서 필요한 좌표 정보만 넘파이 객체로 뽑음\n",
    "        for (x, y) in shape:\n",
    "          cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "# imshow(\"\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1 = ((shape[58] + shape[9])*0.5).round()  # point1 턱 (밑입술 하단 - 턱끝 )\n",
    "point2 = ((shape[3] + shape[49])*0.5).round()  # point2 왼쪽 뺨 (왼쪽 외곽선 - 왼쪽 입술 끝점)\n",
    "point3 = ((shape[15] + shape[55])*0.5).round() # point3 오른쪽 뺨 (오른쪽 외곽선 - 오른쪽 입술 끝점)\n",
    "point4 = shape[31].astype('float64')           # point4 코\n",
    "point5 = ((shape[22] + shape[23])*0.5).round() # point5 눈썹 사이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RGB 모드로 변경 \n",
    "rgb_img = img.convert('RGB') \n",
    "\n",
    "# 지정한 좌표의 색상을 r,g,b 변수에 넣음 \n",
    "r1, g1, b1 = rgb_img.getpixel((point1[0], point1[1]))\n",
    "r2, g2, b2 = rgb_img.getpixel((point2[0], point2[1])) \n",
    "r3, g3, b3 = rgb_img.getpixel((point3[0], point3[1])) \n",
    "r4, g4, b4 = rgb_img.getpixel((point4[0], point4[1])) \n",
    "r5, g5, b5 = rgb_img.getpixel((point5[0], point5[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAABTUlEQVR4nO3aIW5CQRhGUR7BNGUlJd0JCSummhXQFVQ0iC5hMLUg77yEc+yYT938YpYxxgaAxnb2AIBXIroAIdEFCIkuQEh0AUKiCxDaPXv8+b76T/bv7/c2e8Jq7N/fZk9YjcvXefaE1TgcPmZPWI3P42l59ObSBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXILSMMWZvAHgZLl2AkOgChEQXICS6ACHRBQiJLkDoDngBEIdB18pDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# point RGB값 보여주기\n",
    "\n",
    "def plot_colors(hist, centroids):\n",
    "    bar = np.zeros((50, 300, 3), dtype = \"uint8\")\n",
    "    startX = 0\n",
    "\n",
    "    for (percent, color) in zip(hist, centroids):\n",
    "        endX = startX + (percent * 300)\n",
    "        cv2.rectangle(bar, (int(startX), 0), (int(endX), 50),\n",
    "            color.astype(\"uint8\").tolist(), -1)\n",
    "        startX = endX\n",
    "    return bar\n",
    "\n",
    "\n",
    "hist = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "temp = np.array([[r1,g1,b1],[r2,g2,b2],[r3,g3,b3],[r4,g4,b4],[r5,g5,b5]])\n",
    "\n",
    "\n",
    "\n",
    "bar = plot_colors(hist, temp)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(bar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "\n",
    "# RGB -> HSV\n",
    "def revised_rgb_to_hsv(r, g, b):\n",
    "    (h, s, v) = colorsys.rgb_to_hsv(r/255, g/255, b/255)\n",
    "    h *= 360\n",
    "    s *= 100\n",
    "    v *= 100\n",
    "    return round(h), round(s), round(v)\n",
    "\n",
    "h1, s1, v1 = revised_rgb_to_hsv(r1, g1, b1)\n",
    "h2, s2, v2 = revised_rgb_to_hsv(r2, g2, b2)\n",
    "h3, s3, v3 = revised_rgb_to_hsv(r3, g3, b3)\n",
    "h4, s4, v4 = revised_rgb_to_hsv(r4, g4, b4)\n",
    "h5, s5, v5 = revised_rgb_to_hsv(r5, g5, b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로 예측\n",
    "data = pd.read_excel('data2.xlsx', index_col='순번')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['H','S', 'V','R', 'G', 'B']]\n",
    "y = data[['쿨웜']]\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(silent=False, \n",
    "                          booster='gbtree',\n",
    "                          scale_pos_weight=1,\n",
    "                          learning_rate=0.01,  \n",
    "                          colsample_bytree = 0.4,\n",
    "                          subsample = 0.8,\n",
    "                          objective='binary:logistic', \n",
    "                          n_estimators=2000, \n",
    "                          max_depth=5, \n",
    "                          gamma=10, \n",
    "                          seed=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.4, gamma=10, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=2000, n_jobs=0, num_parallel_tree=1,\n",
       "              random_state=777, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=777, silent=False, subsample=0.8, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1 = np.array([h1, s1, v1, r1, g1, b1])\n",
    "point2 = np.array([h2, s2, v2, r2, g2, b2])\n",
    "point3 = np.array([h3, s3, v3, r3, g3, b3])\n",
    "point4 = np.array([h4, s4, v4, r4, g4, b4])\n",
    "point5 = np.array([h5, s5, v5, r5, g5, b5])\n",
    "\n",
    "points = np.array([point1, point2, point3, point4, point5])\n",
    "\n",
    "#정규화\n",
    "points = preprocessing.StandardScaler().fit(points).transform(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1]\n",
      "[[0.66662306 0.33337694]\n",
      " [0.53979635 0.46020362]\n",
      " [0.41561663 0.58438337]\n",
      " [0.766287   0.23371299]\n",
      " [0.3978936  0.6021064 ]]\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(points)\n",
    "predict_proba = model.predict_proba(points)\n",
    "print(predict)\n",
    "print(predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.75688123703003\n",
      "58.43833684921265\n"
     ]
    }
   ],
   "source": [
    "# 쿨톤\n",
    "proba_cool = []\n",
    "for i in range(4):\n",
    "    if predict_proba[i][0] > 0.5:\n",
    "        proba_cool.append(predict_proba[i][0])\n",
    "print(sum(proba_cool)/len(proba_cool)*100)\n",
    "\n",
    "# 웜톤\n",
    "proba_warm = []\n",
    "for i in range(4):\n",
    "    if predict_proba[i][1] > 0.5:\n",
    "        proba_warm.append(predict_proba[i][1])\n",
    "print(sum(proba_warm)/len(proba_warm)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿨톤일 확률이 65.76% 입니다.\n"
     ]
    }
   ],
   "source": [
    "if predict.sum() >= 3:\n",
    "    print(\"웜톤일 확률이 {:.2f}% 입니다.\".format(sum(proba_warm)/len(proba_warm)*100))\n",
    "else:\n",
    "    print(\"쿨톤일 확률이 {:.2f}% 입니다.\".format(sum(proba_cool)/len(proba_cool)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
